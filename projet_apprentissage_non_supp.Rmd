---
title: "Projet d'apprentissage non supervisé"
author: "Marie Guibert - Clémence Chesnais"
date: "`r Sys.Date()`"
output: pdf_document
---

# Environnement de travail

```{r, messsage = FALSE}
library(tidyverse)
library(stargazer)
library(gridExtra)
library(corrplot)
library(cluster)
library(NbClust)
```

# Question 1

## Importation des données

```{r}
d <- read.csv("Pays_donnees.csv",sep=",",dec=".",stringsAsFactors = T,row.names="pays")
str(d)
# summary(d)
```

Dans ce jeu de données, nous pouvons observer 10 variables dont 9 numériques et 1 facteur comprenant les différents pays (individus). Nous avons choisi de transformer la variable pays en facteur pour simplifier nos traitement des données.

## Prétraitement des données

### Données manquantes

```{r}
sum(is.na(d))
```

Le jeu de données ne présentent pas de valeur manquante. Nous n'avons pas besoin de faire de modification de ce point de vue.

### Standardisation des données

Nous pouvons remarquer que les données sont dans des unités différentes et les ordres de grandeur sont très variables. Nous avons donc choisi de standardiser les données.

```{r}
data <- scale(d)
```

Afin de pouvoir analyser ces données, nous allons réaliser des statistiques descriptives de base.

### Statistiques descriptives

On effectue les statistiques descriptives sur les valeurs avant standardisation. 
# DEMANDER AU PROF SI CELA A DU SENS ?

[Résumé des données :]{.underline}

```{r}
# stargazer(d,type="text",title="Résumé des données",out="resume_donnnees.txt")
```

Ce résumé statistique nous permet d'avoir une vue d'ensemble sur les données.\
Notre jeu de données est composé de 167 pays très hétérogènes. En effet, nous pouvons observer une assez grande différence entre le minimum et le maximum de chaque variable, ce qui prouve la diversité de notre échantillon.

[Graphiques :]{.underline}

```{r}
ggplot(data=d, aes(y=enfant_mort)) +
  geom_boxplot(outlier.colour="red", outlier.shape=8,outlier.size=4)+
  labs(title="Nombre de décès d'enfants de moins de 5 ans",y="Nombre de décès pour 1000 naissances")+
  theme(plot.title = element_text(hjust=0.5))
```

```{r}
sante <- ggplot(data=d, aes(y=sante)) + 
  geom_boxplot(outlier.colour="red", outlier.shape=8,outlier.size=4)+
  labs(title="Dépenses totales de santé par habitant",y="Pourcentage du PIB par habitant")+
  theme(plot.title = element_text(hjust=0.5))

esperance <- ggplot(data=d, aes(y=esper_vie)) + 
  geom_boxplot(outlier.colour="red", outlier.shape=8,outlier.size=4)+
  labs(title="Espérance de vie",y="Age")+
  theme(plot.title = element_text(hjust=0.5))

grid.arrange(sante,esperance,ncol=2)
```

```{r}
revenu_net <- ggplot(data=d, aes(y=revenu)) + 
  geom_boxplot(outlier.colour="red", outlier.shape=8,outlier.size=4)+
  labs(title="Revenu net moyen par personne")+
  theme(plot.title = element_text(hjust=0.5))

pib_hab <- ggplot(data=d, aes(y=pib_h)) + 
  geom_boxplot(outlier.colour="red", outlier.shape=8,outlier.size=4)+
  labs(title="PIB par habitant")+
  theme(plot.title = element_text(hjust=0.5))

grid.arrange(revenu_net,pib_hab,ncol=2)
```

```{r}
ggplot(data=d, aes(y=inflation)) + 
  geom_boxplot(outlier.colour="red", outlier.shape=8,outlier.size=4)+
  labs(title="Mesure du taux de croissance annuel du PIB total")+
  theme(plot.title = element_text(hjust=0.5))
```

```{r}
ggplot(data=d, aes(y=fert)) + 
  geom_boxplot(outlier.colour="red", outlier.shape=8,outlier.size=4)+
  labs(title="Nombre moyen d'enfants par femme")+
  theme(plot.title = element_text(hjust=0.5))
```

Imports et Exports :

```{r}
imports <- ggplot(data=d, aes(y=imports)) + 
  geom_boxplot(outlier.colour="red", outlier.shape=8,outlier.size=4)+
  labs(title="Importations de biens et services \npar habitant",y="Pourcentage du PIB par habitant")+
  theme(plot.title = element_text(hjust=0.5))

exports <- ggplot(data=d, aes(y=exports)) + 
  geom_boxplot(outlier.colour="red", outlier.shape=8,outlier.size=4)+
  labs(title="Exportations de biens et services \npar habitant",y="Pourcentage du PIB par habitant")+
  theme(plot.title = element_text(hjust=0.5))

grid.arrange(exports, imports, ncol=2)
```

[Matrice de corrélation :]{.underline}

```{r}
corrplot(cor(d[-1]),method="circle")
```

Grâce à cette matrice de corrélation, nous pouvons observer une corrélation négative, entre l'espérance de vie et le nombre d'enfants par femme. Par ailleurs, une corrélation positive,proche de 1, apparaît entre le PIB par habitant et le revenu net moyen par personne.

# Question 2

[Matrice de dissimilarité :]{.underline}

Afin de chercher les individus similaires, on peut calculer une matrice de distance / dissimilarité.

```{r}
MD <- as.matrix(dist(data,method = "euclidean"))
# MD <- as.matrix(dist(data,method = "minkowski"))
# MD <- as.matrix(dist(data,method = "manhattan"))
which(MD == min(MD[row(MD)!=col(MD)]),arr.ind=TRUE)
```

Avec la méthode de la distance euclidienne, de manhattan et minkowski, les deux pays les plus proches / similaires sont la Pologne et la Croatie.

Dans notre situation, les variables sont quantitatives, nous pouvons donc utiliser une approche en termes de distances. On cherche à partitionner les pays en groupes distincts et homogènes afin de déterminer leur besoin de d'aide. L'objectif est de former des groupes compacts avec une faible variabilité au sein des groupes.

### Première approche : CAH

[Classification Ascendante Hiérarchique :]{.underline}

Cette première représentation nous permet d'observer de potentiels groupes de pays. Ayant beaucoup de variables, cette analyse est un peu plus compliquée et aucune partition ne semble se démarquer.

```{r}
pairs(data)
```

On calcule d'abord la distance euclidienne au carré. Le calcul de la distance euclidienne nous permettra par la suite d'être optimal lors de l'utilisation de la stratégie de Ward.

```{r}
D <- dist(data,method="euclidean")^2
```

[Méthode CAH avec le saut minimal (single linkage) :]{.underline}

```{r}
CAH_min <- hclust(d= D,method="single")
plot(CAH_min)
```

Ce premier dendrogramme n'est pas très explicite et ne nous permet pas de faire un choix de partition clair.

```{r}
plot(rev(CAH_min$height)[1:20],type="b",xlab="Nombre de partitions",ylab="I_W")
```

Cependant, le tracé de la pertie d'inertie nous suggère de choisir une partition en 2 groupes. Nous avons choisi de représenter seulement les 20 premières valeurs pour ne pas "noyer" l'information importante. Chaque coupure correspond à un saut important d'inertie intra-classes.

Faisons maintant les mêmes graphiques avec la méthode de distance de saut maximal (complet linkage).

[Méthode CAH avec le saut maximal :]{.underline}

```{r}
CAH_max <- hclust(d= D,method="complete")
plot(CAH_max)
```

En analysant ce dendrogramme, nous pouvons distinguer 2 ou 3 groupes de pays différents. Le graphique ci-dessous n'est pas très concluant quant à cette hypothèse. Nous avons donc besoin de continuer nos analyses.

```{r}
plot(rev(CAH_max$height)[1:20],type="b",xlab="Nombre de partitions",ylab="I_W")
```

[CAH avec la distance de Ward :]{.underline}

Enfin, avec la distance de ward, on obtient les résultats suivants :

```{r}
CAH_ward <- hclust( d = D,method="ward.D")
plot(CAH_ward,hang=-1)
```

Le dendrogramme nous permet aussi de supposer l'existence de 2 voire 3 groupes.\
Le tracé de la perte d'inertie nous permet de nous pencher vers le choix de 2 groupes.

```{r}
plot(rev(CAH_ward$height)[1:20],type="b",xlab="Nombre de partitions",ylab="I_W")
```

Cependant, cette dernière classification ascendante hiérarchique nous permet de douter de notre hypothèse de partition en 2 groupes. Ce dernier nous incite plutôt à choisir 3 groupes.

# A REVOIR : POURQUOI ON A PAS DE COUDE ???

[Critère automatique à partir du package 'NbClust' :]{.underline}

```{r}
NbClust(data,min.nc = 2,max.nc = 15,method="ward.D",index="all")
```

Cette étape nous permet de conclure que le choix le plus pertinent est une partition en 2 groupes.
Cependant, notre budget étant limité, nous allons devoir réaliser une deuxième classification sur le groupe le plus défavorisé.

# A FAIRE !!

[Représentation graphique des clusters avec la fonction cutree :]{.underline}

La fonction cutree permet de faire apparaitre visuellement les groupes. Dans notre cas, on fixe K = 2 car nous avons choisi de réaliser une partition en 2 groupes.

```{r}
K = 2
gpe.ward = cutree(CAH_ward,k=K)
plot(gpe.ward)
# gpe.ward
```

Sur ce graphique, on remarque correctement 2 groupes distincts.

[Représentation graphique des clusters avec un dendrogramme :]{.underline}

```{r}
K=2
plot(CAH_ward,hang=-1)
rect.hclust(CAH_ward,K,border="blue")
```

[Représentation des groupes avec la fonction clusplot :]{.underline}

```{r}
data  <-  cbind(data,gpe.ward)
clusplot(data,cutree(CAH_ward,K),labels=4)
```

Ce graphe correspond à la représentation des groupes sur les deux premiers axes principaux d'une ACP. De plus, des ellipses de contour autour des groupes sont tracées. Ici, nous pouvons voir 2 groupes. 

### Deuxième approche :  Agrégation autour de centres mobiles


La fonction kmeans donne le résultat de l’algorithme d’agrégation autour des centres mobiles.

```{r}
K = 2 # 2 groupes
c <- kmeans(data,K,nstart=50)
# c
```

La fonction **kmeans** nous permet d'obtenir le partitionnement final. Dans notre cas, elle nous rend 2 clusters composés de 135 et 32 pays. Ici, nous avons initialisé nstart à 50 pour répéter la procédure plusieurs fois et garder la partition avec la plus faible inertie intra classes.
On peut en déduire qu'on a un groupe nécessiteux et l'autre plus aisé.


```{r}
clusplot(data,c$cluster,labels=4)
```
## Autre approche 


# QUELLE EST LA DIFFERENCE AVEC NOTRE 1ERE APPROCHE ??

Calcul de la matrice distance avec la dissimilarité basée sur la corrélation.

```{r}
CorDist = as.dist((1-cor(t(data)))/2)
```

```{r}
CC.ward = hclust(dist(data),method="ward.D")
plot(rev(CC.ward$height),type="b")
plot(CC.ward,hang=-1)
rect.hclust(CC.ward, 2, border ="magenta")
```

```{r}
# gpe = cutree(CC.ward,k=2)
# data$gpecah = as.factor(gpe)
# interpcah = catdes(data,num.var = 8)
# interpcah
```



# CLASSIFICATION SUR PETIT GROUPE (GROUPE PAYS DEFAVORISE) A FAIRE

# ACP A FAIRE
