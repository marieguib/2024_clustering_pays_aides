---
title: "Projet d'apprentissage non supervisé"
author: "Marie Guibert - Clémence Chesnais"
date: "`r Sys.Date()`"
output: pdf_document
---

# Environnement de travail

```{r, messsage = FALSE}
library(tidyverse)
library(stargazer)
library(gridExtra)
library(corrplot)
library(cluster)
library(NbClust)
```

# Question 1

## Importation des données

```{r}
data <- read.csv("Pays_donnees.csv",sep=",",dec=".",stringsAsFactors = T,row.names="pays")
str(data)
# summary(data)
```

Dans ce jeu de données, nous pouvons observer 10 variables dont 9 numériques et 1 facteur comprenant les différents pays (individus). Nous avons choisi de transformer la variable pays en facteur pour simplifier nos traitement des données.


# STANDARDISATION ?

Afin de pouvoir analyser ces données, nous allons réaliser des statistiques descriptives de base.

## Statistiques descriptives

```{r}
sum(is.na(data))
```

Le jeu de données ne présente pas de valeur manquante, nous n'avons pas besoin de faire de modification de ce point de vue.

[Résumé des données :]{.underline}

```{r}
stargazer(data,type="text",title="Résumé des données",out="resume_donnnees.txt")
```

Ce résumé statistique nous permet d'avoir une vue d'ensemble sur les données.\
Notre jeu de données est composé de 167 pays très hétérogènes. En effet, nous pouvons observer une assez grande différence entre le minimum et le maximum de chaque variable, ce qui prouve la diversité de notre échantillon.

[Graphiques :]{.underline}


```{r}
ggplot(data=data, aes(y=enfant_mort)) + 
  geom_boxplot(outlier.colour="red", outlier.shape=8,outlier.size=4)+
  labs(title="Nombre de décès d'enfants de moins de 5 ans",y="Nombre de décès pour 1000 naissances")+
  theme(plot.title = element_text(hjust=0.5))
```

```{r}
sante <- ggplot(data=data, aes(y=sante)) + 
  geom_boxplot(outlier.colour="red", outlier.shape=8,outlier.size=4)+
  labs(title="Dépenses totales de santé par habitant",y="Pourcentage du PIB par habitant")+
  theme(plot.title = element_text(hjust=0.5))

esperance <- ggplot(data=data, aes(y=esper_vie)) + 
  geom_boxplot(outlier.colour="red", outlier.shape=8,outlier.size=4)+
  labs(title="Espérance de vie",y="Age")+
  theme(plot.title = element_text(hjust=0.5))

grid.arrange(sante,esperance,ncol=2)
```

```{r}
revenu_net <- ggplot(data=data, aes(y=revenu)) + 
  geom_boxplot(outlier.colour="red", outlier.shape=8,outlier.size=4)+
  labs(title="Revenu net moyen par personne")+
  theme(plot.title = element_text(hjust=0.5))

pib_hab <- ggplot(data=data, aes(y=pib_h)) + 
  geom_boxplot(outlier.colour="red", outlier.shape=8,outlier.size=4)+
  labs(title="PIB par habitant")+
  theme(plot.title = element_text(hjust=0.5))

grid.arrange(revenu_net,pib_hab,ncol=2)
```

```{r}
ggplot(data=data, aes(y=inflation)) + 
  geom_boxplot(outlier.colour="red", outlier.shape=8,outlier.size=4)+
  labs(title="Mesure du taux de croissance annuel du PIB total")+
  theme(plot.title = element_text(hjust=0.5))
```

```{r}
ggplot(data=data, aes(y=fert)) + 
  geom_boxplot(outlier.colour="red", outlier.shape=8,outlier.size=4)+
  labs(title="Nombre moyen d'enfants par femme")+
  theme(plot.title = element_text(hjust=0.5))
```


Imports et Exports :
```{r}
imports <- ggplot(data=data, aes(y=imports)) + 
  geom_boxplot(outlier.colour="red", outlier.shape=8,outlier.size=4)+
  labs(title="Importations de biens et services \npar habitant",y="Pourcentage du PIB par habitant")+
  theme(plot.title = element_text(hjust=0.5))

exports <- ggplot(data=data, aes(y=exports)) + 
  geom_boxplot(outlier.colour="red", outlier.shape=8,outlier.size=4)+
  labs(title="Exportations de biens et services \npar habitant",y="Pourcentage du PIB par habitant")+
  theme(plot.title = element_text(hjust=0.5))

grid.arrange(exports, imports, ncol=2)
```
[Matrice de corrélation :]{.underline}

```{r}
corrplot(cor(data[-1]),method="circle")
```
Grâce à cette matrice de corrélation, nous pouvons observer une corrélation négative, entre l'espérance de vie et le nombre d'enfants par femme. Par ailleurs, une corrélation positive,proche de 1, apparaît entre le PIB par habitant et le revenu net moyen par personne.


# Question 2

[Matrice de dissimilarité :]{.underline}


Afin de chercher les individus similaires, on peut calculer une matrice de distance / dissimilarité.

```{r}
MD <- as.matrix(dist(data,method = "euclidean"))
# MD <- as.matrix(dist(data,method = "minkowski"))
# MD <- as.matrix(dist(data,method = "manhattan"))
which(MD == min(MD[row(MD)!=col(MD)]),arr.ind=TRUE)
```
Avec la distance euclidienne, de manhattan et mikowski, les deux pays les plus proches / similaires sont le Burkina Faso et la Guinée-Bissau. 


[Classification Ascendante Hiérarchique :]{.underline}

Cette première représentation nous permet d'observer de potentiels groupes de pays. Ayant beaucoup de variables, cette analyse est un peu plus compliquée et aucune partition ne semble se démarquer.

```{r}
pairs(data)
```


On calcule d'abord la distance euclidienne au carré : 

```{r}
D <- dist(data,method="euclidean")^2
```

Méthode CAH avec le saut minimal (single linkage) : 

```{r}
CAH_min <- hclust(d= D,method="single")
plot(CAH_min)
```
Ce premier dendrogramme n'est pas très explicite et ne nous permet pas de faire un choix de partition clair. 

```{r}
plot(rev(CAH_min$height)[1:20],type="b",xlab="Nombre de partitions",ylab="I_W")
```

Cependant, le tracé de la pertie d'inertie nous suggère de choisir une partition en 3 ou 4 groupes. Nous avons choisi de représenter seulement les 20 premières valeurs pour ne pas "noyer" l'information importante. Chaque coupure correspond à un saut important d'inertie intra-classes. 


Faisons maintant les mêmes graphiques avec la méthode de distance de saut maximal (complet linkage):

```{r}
CAH_max <- hclust(d= D,method="complete")
plot(CAH_max)
```

En analysant ce dendrogramme, nous pouvons distinguer 3 groupes de pays différents. De plus, le graphique suivant nous permet de confirmer cette hypothèse. 

```{r}
plot(rev(CAH_max$height)[1:20],type="b",xlab="Nombre de partitions",ylab="I_W")
```

Enfin, avec la distance de ward, on obtient les résultats suivants: 

```{r}
CAH_ward <- hclust( d = D,method="ward.D")
plot(CAH_ward,hang=-1)
```

Le tracé de la parte d'inertie nous permet de distinguer 3 groupes. 
```{r}
plot(rev(CAH_ward$height)[1:20],type="b",xlab="Nombre de partitions",ylab="I_W")
```

Ainsi, cette dernière classification ascendante hiérarchique nous permet de confirmer notre hypothèse de partition.

[Représentation graphique des groupes avec un dendrogramme :]{.underline}

Ensuite, ce dendrogramme nous permet de distinguer clairement les groupes de pays. Notre hypothèse est donc valide.

```{r}
K=3
plot(CAH_ward,hang=-1)
rect.hclust(CAH_ward,K,border="blue")
```

[Représentation graphique des clusters avec la fonction cutree :]{.underline}

La fonction cutree permet de faire apparaitre visuellement les groupes.
Dans notre cas, on fixe K = 3 car nous avons choisi de réaliser une partition en 3 groupes.

```{r}
gpe.ward = cutree(CAH_ward,k=K)
plot(gpe.ward)
```

Sur ce graphique, on remarque correctement 3 groupes distincts.
 
 
[Représentation des groupes avec la fonction clusplot :]{.underline}

```{r}
data$gpe.ward <- gpe.ward
clusplot(data,cutree(CAH_ward,K),labels=4)
```
 
Ce graphe correspond à la représentation des groupes sur les deux premiers axes principaux d'une ACP. De plus, des ellipses de contour autour des groupes sont tracées. Ici, nous pouvons voir 3 groupes. En colorant les points avec leur vraie classe, nous pouvons observer que 

# A FINIR 

[Agrégation autour de centres mobiles :]{.underline}

```{r}
K = 3 # 3 groupes
c <- kmeans(data,K,nstart=50)
c
```
La fonction **kmeans** nous permet d'obtenir le partitionnement final. Dans notre cas, elle nous rend 3 clusters composés de 35, 109 et 23 individus. Ici, nous avons initialisé nstart à 50 pour répéter la procédure plusieurs fois et garder la partition avec la plus faible inertie intra classes.

```{r}
clusplot(data,c$cluster,labels=4)
```

```{r}

```

